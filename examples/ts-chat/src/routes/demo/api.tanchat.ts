import { createFileRoute } from "@tanstack/react-router";
import { AI } from "@tanstack/ai";
import { AnthropicAdapter } from "@tanstack/ai-anthropic";
import type { Tool } from "@tanstack/ai";

import guitars from "@/data/example-guitars";

const SYSTEM_PROMPT = `You are a helpful assistant for a store that sells guitars.

You can use the following tools to help the user:

- getGuitars: Get all guitars from the database
- recommendGuitar: Recommend a guitar to the user
`;

// Define tools with execute functions
const tools: Tool[] = [
  {
    type: "function",
    function: {
      name: "getGuitars",
      description: "Get all products from the database",
      parameters: {
        type: "object",
        properties: {},
        required: [],
      },
    },
    execute: async () => {
      return JSON.stringify(guitars);
    },
  },
  {
    type: "function",
    function: {
      name: "recommendGuitar",
      description: "Use this tool to recommend a guitar to the user",
      parameters: {
        type: "object",
        properties: {
          id: {
            type: "string",
            description: "The id of the guitar to recommend",
          },
        },
        required: ["id"],
      },
    },
    execute: async ({ id }: { id: string }) => {
      return JSON.stringify({ id });
    },
  },
];

export const Route = createFileRoute("/demo/api/tanchat")({
  server: {
    handlers: {
      POST: async ({ request }) => {
        try {
          const { messages } = await request.json();

          // Initialize AI with Anthropic
          const ai = new AI(
            new AnthropicAdapter({
              apiKey: process.env.ANTHROPIC_API_KEY!,
            })
          );

          // Add system message if not present
          const allMessages =
            messages[0]?.role === "system"
              ? messages
              : [{ role: "system", content: SYSTEM_PROMPT }, ...messages];

          // Set up streaming response
          const encoder = new TextEncoder();
          const stream = new ReadableStream({
            async start(controller) {
              try {
                // streamChat automatically handles tool execution!
                for await (const chunk of ai.streamChat({
                  model: "claude-3-5-sonnet-20241022",
                  messages: allMessages,
                  temperature: 0.7,
                  tools,
                  toolChoice: "auto",
                  maxIterations: 5, // Limit tool calling loops
                })) {
                  // Just stream the chunks - tools are executed automatically
                  controller.enqueue(
                    encoder.encode(`data: ${JSON.stringify(chunk)}\n\n`)
                  );
                }

                controller.enqueue(encoder.encode("data: [DONE]\n\n"));
                controller.close();
              } catch (error: any) {
                controller.enqueue(
                  encoder.encode(
                    `data: ${JSON.stringify({
                      type: "error",
                      error: { message: error.message },
                    })}\n\n`
                  )
                );
                controller.close();
              }
            },
          });

          return new Response(stream, {
            headers: {
              "Content-Type": "text/event-stream",
              "Cache-Control": "no-cache",
              Connection: "keep-alive",
            },
          });
        } catch (error) {
          console.error("Chat API error:", error);
          return new Response(
            JSON.stringify({ error: "Failed to process chat request" }),
            {
              status: 500,
              headers: { "Content-Type": "application/json" },
            }
          );
        }
      },
    },
  },
});
